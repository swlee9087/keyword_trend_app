# streamlit_naver_api.py

import requests
import pandas as pd
import streamlit as st
import json
import math
from datetime import datetime, timedelta
from env_loader import load_naver_credentials
from log_util import logger

def chunk_keywords(keywords, chunk_size=5, group_size=20):
    """í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ë¥¼ Naver APIì— ë§ê²Œ ê·¸ë£¹ë³„ë¡œ ë‚˜ëˆ„ê¸°"""
    chunks = []
    for i in range(0, len(keywords), group_size):
        group_keywords = keywords[i:i+group_size]
        group_name = group_keywords[0]
        chunks.append({"groupName": group_name, "keywords": group_keywords})
    return [chunks[i:i+chunk_size] for i in range(0, len(chunks), chunk_size)]

def fetch_naver_trends(keyword_groups_batch, start_date, end_date, client_id, client_secret):
    url = "https://openapi.naver.com/v1/datalab/search"

    headers = {
        "X-Naver-Client-Id": client_id,
        "X-Naver-Client-Secret": client_secret,
        "Content-Type": "application/json"
    }

    data = {
        "startDate": start_date,
        "endDate": end_date,
        "timeUnit": "date",
        "keywordGroups": keyword_groups_batch
    }

    response = requests.post(url, headers=headers, data=json.dumps(data))
    if response.status_code == 200:
        logger.log(f">>>>>> Naver API í˜¸ì¶œ ì„±ê³µ: status_code={response.status_code}")
        return response.json()
    else:
        error_msg = f">>> Naver API í˜¸ì¶œ ì‹¤íŒ¨: {response.status_code}, {response.text}"
        logger.log(error_msg)
        raise Exception(error_msg)

def collect_trend_data(keywords, days=7):
    st.subheader("ğŸ” ë„¤ì´ë²„ ê²€ìƒ‰ì–´ íŠ¸ë Œë“œ ë°ì´í„° ìˆ˜ì§‘")
    
    #ì¸ì¦
    try:
        client_id, client_secret = load_naver_credentials()
        st.caption("âœ… .envì—ì„œ ì¸ì¦ ì •ë³´ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
        logger.log(">>>>>> ì¸ì¦ ì •ë³´ ë¡œë“œ ì„±ê³µ")
    except Exception as e:
        st.error(str(e))
        logger.log(f">>> ì¸ì¦ ì •ë³´ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

    # ë‚ ì§œ 
    today = datetime.today().date()
    start_date = (today - timedelta(days=days)).isoformat()
    end_date = today.isoformat()
    logger.log(f">>>>>> ë°ì´í„° ìˆ˜ì§‘ ê¸°ê°„: {start_date} ~ {end_date}, ì´ í‚¤ì›Œë“œ ìˆ˜: {len(keywords)}")

    # í‚¤ì›Œë“œ ê·¸ë£¹ ë°°ì¹˜
    keyword_batches = chunk_keywords(keywords)
    logger.log(f">>>>>> í‚¤ì›Œë“œ ê·¸ë£¹ ë°°ì¹˜ ìˆ˜: {len(keyword_batches)}")
    
    # API í˜¸ì¶œ
    all_data = []
    with st.spinner("ë„¤ì´ë²„ APIë¡œ ë°ì´í„° ìˆ˜ì§‘ ì¤‘..."):
        for idx, batch in enumerate(keyword_batches, 1):
            names = [g["groupName"] for g in batch]
            logger.log(f"â–¶ï¸ ë°°ì¹˜ {idx}/{len(keyword_batches)} í˜¸ì¶œ: {names}")
            # logger.log(f">>>>>> [ë°°ì¹˜ {batch}/{len(keyword_batches)}] í˜¸ì¶œí•  ê·¸ë£¹: {[g['groupName'] for g in batch]}")
            try:
                result = fetch_naver_trends(batch, start_date, end_date, client_id, client_secret)
                for group in result['results']:
                    df = pd.DataFrame(group['data'])
                    df['group'] = group['title']
                    all_data.append(df)
                # logger.log(f">>>>>>ê·¸ë£¹ '{group['title']}' ë°ì´í„° ìˆ˜ì§‘: {len(group['data'])}ê±´")
                logger.log(f">>>>>> ë°°ì¹˜ {idx} ì™„ë£Œ, rows: {sum(len(g['data']) for g in result['results'])}")
            except Exception as e:
                st.warning(f"âŒ ë°°ì¹˜ {idx} ì‹¤íŒ¨: {e}")
                logger.log(f">>>>>> ë°°ì¹˜ {idx} exception: {e}")

    if all_data:
        full_df = pd.concat(all_data, ignore_index=True)
        
        # ì¹¼ëŸ¼ ì •ë¦¬
        cols_before = full_df.columns.tolist()
        # ì¹¼ëŸ¼ëª… ì •ë¦¬. ë¦¬í„´ëœ ì¹¼ëŸ¼ëª…ì— í¬í•¨ëœ ë”°ì˜´í‘œ, ê³µë°± ì œê±°
        cleaned_cols = [c.strip().strip('"').strip("'") for c in cols_before]
        full_df.columns = cleaned_cols
        st.write("âš™ï¸ ìˆ˜ì§‘ëœ ì»¬ëŸ¼ë“¤:", cleaned_cols)
        logger.log(f"sanitized columns: {cleaned_cols}")
        # logger.log(f">>>>>> collect_trend_data columns: {full_df.columns.tolist()}")
    
        # period/date í†µì¼
        cols = full_df.columns.tolist()
        #period ë˜ëŠ” dateê³„ì—´ ì»¬ëŸ¼ íƒìƒ‰
        date_cand = [c for c in cols if c.lower() in ('period', 'date')]
        if not date_cand: 
            st.error(f"âŒ 'period' ë˜ëŠ” 'date' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {cols}")
            logger.log(f">>> period column missing, cols={cols}")
            return None
        src = date_cand[0]
        if src != 'period':
            full_df = full_df.rename(columns={src: 'period'})
            logger.log(f">>>>>> '{src}' â†’ 'period' ë³€í™˜ ì™„ë£Œ")
        full_df['period'] = pd.to_datetime(full_df['period'], errors="coerce")
        logger.log(">>>>>> 'period' datetime ë³€í™˜ ì™„ë£Œ")
        
        # ratio í†µì¼
        if "ratio" not in full_df.columns:
            num_cols = full_df.select_dtypes(include="number").columns.tolist()
            num_cols = [c for c in num_cols if c != "period"]
            if not num_cols:
                st.error(f"âŒ 'ratio' ì»¬ëŸ¼ì´ ì—†ê³ , ìˆ«ìí˜• ì»¬ëŸ¼ë„ ì—†ìŠµë‹ˆë‹¤: {cols}")
                logger.log(f"âŒ ratio missing & no numeric: {cols}")
                return None
            full_df = full_df.rename(columns={num_cols[0]: "ratio"})
            logger.log(f"ğŸ”„ '{num_cols[0]}' â†’ 'ratio'")
        # to numeric
        full_df["ratio"] = pd.to_numeric(full_df["ratio"], errors="coerce")
        logger.log("ğŸ”¢ 'ratio' numeric ë³€í™˜ ì™„ë£Œ")

        # group í†µì¼
        if "group" not in full_df.columns:
            title_cand = [c for c in cols if "title" in c.lower()]
            if title_cand:
                full_df = full_df.rename(columns={title_cand[0]: "group"})
                logger.log(f"ğŸ”„ '{title_cand[0]}' â†’ 'group'")
            else:
                st.error(f"âŒ 'group' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {cols}")
                logger.log(f"âŒ group missing: {cols}")
                return None
            
        # 9) ì™„ë£Œ
        valid_rows = len(full_df)
        st.success(f"âœ… ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ ({valid_rows} rows)")
        logger.log(f">>>>>> NAVER ì „ì²´ ìˆ˜ì§‘ ì™„ë£Œ: {valid_rows} rows")
        return full_df
    
    else:
        st.error("âŒ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        logger.log(">>> ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
        return None
